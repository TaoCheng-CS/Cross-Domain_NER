### use # to comment out the configure item


### I/O ###
source_train_dir=data/conll03NER/train.bmes
source_dev_dir=data/conll03NER/dev.bmes
source_test_dir=data/conll03NER/test.bmes

target_train_dir=data/news_tech/my.bies#not to train NER model, just for the form
target_test_dir_1=data/news_tech/tech_test#the target-test dataset
target_test_dir_2=data/news_tech/try#tried data, just for the form

source_lm_dir=data/large_news_raw.train
target_lm_dir=data/large_news_tech.train

model_dir=data/conll03NER/lstm_crf_ner

word_emb_dir=data/glove.6B.100d.txt

task_emb_save_dir=data/conll03NER/sample.task.emb.save
domain_emb_save_dir=data/conll03NER/sample.domain.emb.save

load_model_dir=data/conll03NER/lstmcrf.model

number_normalized=True

word_emb_dim=100
char_emb_dim=30
task_emb_dim=8
domain_emb_dim=8
sample_num=50

###NetworkConfiguration###
use_crf_sl=True
use_crf_lm=False
use_lm_sample = True
use_char=True
word_seq_feature=LSTM
char_seq_feature=CNN


###TrainingSetting###
status=train
optimizer=RMSPROP
iteration=100
batch_size=10
ave_batch_loss=True

###Hyperparameters###
cnn_layer=4
char_hidden_dim=50
hidden_dim=200
dropout=0.5
lstm_layer=1
bilstm=True
learning_rate=0.001
learning_rate_cpg=0.001
lr_decay=0.05
momentum=0
l2=1e-8
